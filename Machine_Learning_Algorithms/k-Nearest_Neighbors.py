"""
Алгоритм k-ближайших соседей (k-NN) — это метод машинного обучения, который используется для классификации и регрессии.
В обоих случаях входные данные состоят из k ближайших обучающих примеров в пространстве признаков.

Классификация k-NN: объект классифицируется путем большинства голосов его соседей, с объектом присваивается класс,
наиболее часто встречающийся среди его k ближайших соседей (k — положительное целое число, обычно маленькое).
Если k=1, то объект просто присваивается классу его ближайшего соседа.

Регрессия k-NN: значение объекта предсказывается на основе среднего значений его k ближайших соседей.

Основные шаги алгоритма k-NN:
1) Выбрать число k ближайших соседей.
2) Вычислить расстояние между объектом и каждым из обучающих примеров.
3) Отобрать k обучающих примеров, расстояние до которых минимально.
4) Для классификации: присвоить объекту тот класс, который наиболее часто встречается среди k ближайших соседей.
5) Для регрессии: присвоить объекту среднее значение по его k ближайшим соседям.

Расстояние обычно измеряется с помощью евклидового расстояния, но могут использоваться и другие метрики, такие как
Манхэттенское или Чебышевское расстояние.

В Python алгоритм k-NN можно легко реализовать с помощью библиотеки scikit-learn. Вот пример классификации k-NN:
"""
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Загрузка набора данных Iris
iris = load_iris()
X, y = iris.data, iris.target

# Разделение данных на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Создание экземпляра k-NN классификатора с k=3
knn = KNeighborsClassifier(n_neighbors=3)

# Обучение классификатора
knn.fit(X_train, y_train)

# Предсказание на тестовых данных
predictions = knn.predict(X_test)

# Оценка точности
accuracy = accuracy_score(y_test, predictions)
print(f'Accuracy of k-NN classifier: {accuracy:.2f}')

"""
В этом примере используется набор данных Iris для создания модели k-NN с k=3. Модель обучается на обучающем наборе 
данных и затем тестируется на тестовом наборе, после чего вычисляется точность классификации.
"""